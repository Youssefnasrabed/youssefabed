{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(\"Python Version:\", sys.version, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle: Saving Objects for Later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often in data science, we'll create some **model or some version of our data and want to use it later**. We have many options - we can save the coefficients, or save the data to csv, or...\n",
    "\n",
    "Actually, we don't have that many options. \n",
    "\n",
    "One way to overcome that is to save the python object to a file as a serialized object. That means we convert the entire object to a bunch of bytes, save those bytes into a file, and then have the ability to unpack those bytes back into their original format later. \n",
    "\n",
    "This is done by a module called `pickle`. Let's see it in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "\n",
    "lots_of_noise = {\n",
    "    'CA': [random.randint(0,65) for _ in range(100)],\n",
    "    'IL': [random.randint(0,65) for _ in range(50)],\n",
    "    'NY': [random.randint(0,65) for _ in range(90)],\n",
    "    'WA': [random.randint(0,65) for _ in range(33)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CA': [4, 61, 2, 3, 2, 26, 63, 5, 6, 52, 5, 15, 50, 56, 57, 62, 30, 45, 38, 19, 65, 7, 63, 35, 4, 9, 5, 57, 7, 38, 56, 64, 17, 14, 19, 59, 54, 49, 34, 12, 41, 6, 32, 24, 28, 16, 8, 45, 23, 62, 58, 22, 35, 20, 65, 1, 24, 27, 29, 54, 61, 26, 60, 27, 29, 45, 55, 58, 53, 57, 56, 45, 24, 12, 57, 30, 35, 65, 13, 57, 28, 16, 28, 4, 57, 58, 0, 31, 4, 27, 11, 63, 26, 23, 16, 23, 41, 43, 10, 59], 'IL': [37, 16, 8, 63, 39, 52, 23, 23, 11, 45, 5, 41, 52, 23, 7, 44, 25, 4, 46, 1, 24, 18, 47, 45, 6, 41, 30, 18, 46, 46, 47, 63, 15, 13, 27, 17, 58, 3, 34, 53, 62, 2, 7, 11, 61, 17, 9, 37, 25, 3], 'NY': [28, 1, 28, 30, 4, 52, 10, 8, 16, 6, 7, 19, 63, 15, 30, 19, 42, 43, 12, 14, 53, 30, 11, 15, 8, 37, 32, 4, 41, 24, 1, 47, 1, 19, 1, 27, 22, 54, 18, 50, 29, 37, 50, 63, 9, 54, 49, 63, 51, 43, 3, 5, 15, 55, 60, 53, 2, 56, 0, 50, 15, 31, 63, 0, 62, 40, 4, 41, 34, 45, 51, 42, 8, 29, 61, 48, 0, 1, 3, 17, 17, 59, 65, 2, 23, 59, 46, 35, 65, 32], 'WA': [37, 37, 4, 28, 13, 0, 51, 18, 29, 63, 35, 57, 14, 45, 26, 9, 18, 25, 13, 57, 25, 46, 16, 23, 20, 65, 22, 25, 28, 1, 29, 21, 63]}\n"
     ]
    }
   ],
   "source": [
    "print(lots_of_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable        Type      Data/Info\n",
      "-----------------------------------\n",
      "lots_of_noise   dict      n=4\n",
      "pickle          module    <module 'pickle' from 'C:<...>aconda3\\\\lib\\\\pickle.py'>\n",
      "random          module    <module 'random' from 'C:<...>aconda3\\\\lib\\\\random.py'>\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in this `whos` command that the object `lots_of_noise` exists and is a `dict` with 4 keys. Nice. Now let's look at our file system and verify that there isn't a file called `noise.pickle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\youss'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd() # \"getting working directoray\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D Objects\n",
      "AppData\n",
      "Application Data\n",
      "Contacts\n",
      "Cookies\n",
      "Documents\n",
      "Downloads\n",
      "Favorites\n",
      "Google Drive\n",
      "IntelGraphicsProfiles\n",
      "Links\n",
      "Local Settings\n",
      "MicrosoftEdgeBackups\n",
      "Music\n",
      "My Documents\n",
      "NTUSER.DAT\n",
      "NTUSER.DAT{e7a49069-cf8b-11e9-9cd1-acd5641c9dbb}.TxR.0.regtrans-ms\n",
      "NTUSER.DAT{e7a49069-cf8b-11e9-9cd1-acd5641c9dbb}.TxR.1.regtrans-ms\n",
      "NTUSER.DAT{e7a49069-cf8b-11e9-9cd1-acd5641c9dbb}.TxR.2.regtrans-ms\n",
      "NTUSER.DAT{e7a49069-cf8b-11e9-9cd1-acd5641c9dbb}.TxR.blf\n",
      "NTUSER.DAT{e7a4906a-cf8b-11e9-9cd1-acd5641c9dbb}.TM.blf\n",
      "NTUSER.DAT{e7a4906a-cf8b-11e9-9cd1-acd5641c9dbb}.TMContainer00000000000000000001.regtrans-ms\n",
      "NTUSER.DAT{e7a4906a-cf8b-11e9-9cd1-acd5641c9dbb}.TMContainer00000000000000000002.regtrans-ms\n",
      "NetHood\n",
      "OneDrive\n",
      "PrintHood\n",
      "PycharmProjects\n",
      "Recent\n",
      "Rlibrary\n",
      "Saved Games\n",
      "Searches\n",
      "SendTo\n",
      "Start Menu\n",
      "Templates\n",
      "Videos\n",
      "anaconda3\n",
      "ansel\n",
      "comprehension.ipynb\n",
      "data_sample.csv\n",
      "dictionaries mod.ipynb\n",
      "dictionaries.ipynb\n",
      "errors_exceptions.ipynb\n",
      "modules_packages mod 1.ipynb\n",
      "noise.pickle\n",
      "ntuser.dat.LOG1\n",
      "ntuser.dat.LOG2\n",
      "ntuser.ini\n",
      "pickling mod.ipynb\n",
      "pickling.ipynb\n",
      "rlib\n",
      "sets_tuples.ipynb\n",
      "string_methods.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls # \"list all files in working directory\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we're ready to create a file and write the bytes to it. To do this with `pickle`, we use python's read-write streamer `open` and create a writable-binary (`wb`) file. We'll then use `pickle.dump` to put an object into that file as a string of bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('noise.pickle', 'wb') as to_write: # \" wb is for saving in writable-binary\"\n",
    "    pickle.dump(lots_of_noise, to_write) # \" here we save lots_of_noise as binary file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D Objects\n",
      "AppData\n",
      "Application Data\n",
      "Contacts\n",
      "Cookies\n",
      "Documents\n",
      "Downloads\n",
      "Favorites\n",
      "Google Drive\n",
      "IntelGraphicsProfiles\n",
      "Links\n",
      "Local Settings\n",
      "MicrosoftEdgeBackups\n",
      "Music\n",
      "My Documents\n",
      "NTUSER.DAT\n",
      "NTUSER.DAT{e7a49069-cf8b-11e9-9cd1-acd5641c9dbb}.TxR.0.regtrans-ms\n",
      "NTUSER.DAT{e7a49069-cf8b-11e9-9cd1-acd5641c9dbb}.TxR.1.regtrans-ms\n",
      "NTUSER.DAT{e7a49069-cf8b-11e9-9cd1-acd5641c9dbb}.TxR.2.regtrans-ms\n",
      "NTUSER.DAT{e7a49069-cf8b-11e9-9cd1-acd5641c9dbb}.TxR.blf\n",
      "NTUSER.DAT{e7a4906a-cf8b-11e9-9cd1-acd5641c9dbb}.TM.blf\n",
      "NTUSER.DAT{e7a4906a-cf8b-11e9-9cd1-acd5641c9dbb}.TMContainer00000000000000000001.regtrans-ms\n",
      "NTUSER.DAT{e7a4906a-cf8b-11e9-9cd1-acd5641c9dbb}.TMContainer00000000000000000002.regtrans-ms\n",
      "NetHood\n",
      "OneDrive\n",
      "PrintHood\n",
      "PycharmProjects\n",
      "Recent\n",
      "Rlibrary\n",
      "Saved Games\n",
      "Searches\n",
      "SendTo\n",
      "Start Menu\n",
      "Templates\n",
      "Videos\n",
      "anaconda3\n",
      "ansel\n",
      "comprehension.ipynb\n",
      "data_sample.csv\n",
      "dictionaries mod.ipynb\n",
      "dictionaries.ipynb\n",
      "errors_exceptions.ipynb\n",
      "modules_packages mod 1.ipynb\n",
      "noise.pickle\n",
      "ntuser.dat.LOG1\n",
      "ntuser.dat.LOG2\n",
      "ntuser.ini\n",
      "pickling mod.ipynb\n",
      "pickling.ipynb\n",
      "rlib\n",
      "sets_tuples.ipynb\n",
      "string_methods.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's delete `lots_of_noise` and prove to ourselves it doesn't exist in Python's memory anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lots_of_noise # \"deleting file from working dirctry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable   Type              Data/Info\n",
      "--------------------------------------\n",
      "os         module            <module 'os' from 'C:\\\\Us<...>\\\\anaconda3\\\\lib\\\\os.py'>\n",
      "pickle     module            <module 'pickle' from 'C:<...>aconda3\\\\lib\\\\pickle.py'>\n",
      "random     module            <module 'random' from 'C:<...>aconda3\\\\lib\\\\random.py'>\n",
      "to_write   BufferedWriter    <_io.BufferedWriter name='noise.pickle'>\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lots_of_noise' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-69f22b4d5ca8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlots_of_noise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'lots_of_noise' is not defined"
     ]
    }
   ],
   "source": [
    "print(lots_of_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lovely. It's dead forever. Or is it?\n",
    "\n",
    "Let's open that `noise.pickle` file with read-binary (`rb`) mode. Then we'll ask pickle to retrieve the file with `pickle.load` and store it back in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('noise.pickle','rb') as read_file:\n",
    "    new_noise = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random noise lives! We retrieved the entire structure from file. Nice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okay, but I don't use dictionaries... I use pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yay</th>\n",
       "      <th>specific</th>\n",
       "      <th>column</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.312334</td>\n",
       "      <td>9.380422</td>\n",
       "      <td>-2.128780</td>\n",
       "      <td>-6.248575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.234700</td>\n",
       "      <td>-9.990703</td>\n",
       "      <td>-1.003405</td>\n",
       "      <td>3.517545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.871856</td>\n",
       "      <td>9.845001</td>\n",
       "      <td>-8.450027</td>\n",
       "      <td>-0.573264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.045842</td>\n",
       "      <td>1.567289</td>\n",
       "      <td>6.962307</td>\n",
       "      <td>-4.939450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.028680</td>\n",
       "      <td>7.657878</td>\n",
       "      <td>-0.718521</td>\n",
       "      <td>-9.097369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Yay  specific    column     names\n",
       "0 -4.312334  9.380422 -2.128780 -6.248575\n",
       "1  0.234700 -9.990703 -1.003405  3.517545\n",
       "2 -0.871856  9.845001 -8.450027 -0.573264\n",
       "3 -6.045842  1.567289  6.962307 -4.939450\n",
       "4  5.028680  7.657878 -0.718521 -9.097369"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.random.uniform(-10,10, size=(100,4)), columns=['Yay','specific','column','names'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my_dataframe.pickle', 'wb') as to_write: # \"we sotred my_dataframe\"\n",
    "    pickle.dump(df, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-3975f6306adf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "del df\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yay</th>\n",
       "      <th>specific</th>\n",
       "      <th>column</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.312334</td>\n",
       "      <td>9.380422</td>\n",
       "      <td>-2.128780</td>\n",
       "      <td>-6.248575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.234700</td>\n",
       "      <td>-9.990703</td>\n",
       "      <td>-1.003405</td>\n",
       "      <td>3.517545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.871856</td>\n",
       "      <td>9.845001</td>\n",
       "      <td>-8.450027</td>\n",
       "      <td>-0.573264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.045842</td>\n",
       "      <td>1.567289</td>\n",
       "      <td>6.962307</td>\n",
       "      <td>-4.939450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.028680</td>\n",
       "      <td>7.657878</td>\n",
       "      <td>-0.718521</td>\n",
       "      <td>-9.097369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Yay  specific    column     names\n",
       "0 -4.312334  9.380422 -2.128780 -6.248575\n",
       "1  0.234700 -9.990703 -1.003405  3.517545\n",
       "2 -0.871856  9.845001 -8.450027 -0.573264\n",
       "3 -6.045842  1.567289  6.962307 -4.939450\n",
       "4  5.028680  7.657878 -0.718521 -9.097369"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('my_dataframe.pickle','rb') as read_file: # \"we open back my_dataframe\"\n",
    "    new_df = pickle.load(read_file)\n",
    "    \n",
    "new_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle is a great tool. One recommended way of using it is to make it an end point of every step in your process. Example:\n",
    "\n",
    "* I got my data! Nice. Pickle it and stop your \"getting the data\" notebook.\n",
    "* Load your data from pickle. Clean it. Save your clean data to a new pickle.\n",
    "* Load your cleaned_data pickle. Do analysis and visualize it.\n",
    "\n",
    "This can provide natural \"pick-up-where-I-left-off-but-before-I-broke-my-data\" points. It's a great way to control the flow of your data.\n",
    "\n",
    "#### Resources\n",
    "\n",
    "https://docs.python.org/3.7/library/pickle.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
